{"cells":[{"cell_type":"code","source":["!pip3 install -q transformers gradio"],"metadata":{"id":"lds3LP_so7AP","executionInfo":{"status":"ok","timestamp":1699962923078,"user_tz":0,"elapsed":33499,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bde88099-0ac7-4f6e-c38e-e48ec4f0c8d3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eEhRvcjU2fN"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","from transformers import TFAutoModelForSequenceClassification\n","from transformers import AutoTokenizer, AutoConfig\n","import numpy as np\n","from scipy.special import softmax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCGaBcFuU2fS"},"outputs":[],"source":["model_path = f\"Afia-manubea/FineTuned-DistilBert-Model\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","config = AutoConfig.from_pretrained(model_path)\n","model = AutoModelForSequenceClassification.from_pretrained(model_path)"]},{"cell_type":"code","source":["from transformers import pipeline\n","classifier = pipeline(\"text-classification\", model= f\"Afia-manubea/FineTuned-DistilBert-Model\")"],"metadata":{"id":"YFlDMI2ABRBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nRG5zaeU2fT"},"outputs":[],"source":["# Preprocess text (username and link placeholders)\n","def preprocess(text):\n","    new_text = []\n","    for t in text.split(\" \"):\n","        t = '@user' if t.startswith('@') and len(t) > 1 else t\n","        t = 'http' if t.startswith('http') else t\n","        new_text.append(t)\n","    return \" \".join(new_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2LueGTNU2fU"},"outputs":[],"source":["# Input preprocessing\n","text = \"This covid came with its own agenda\"\n","text = preprocess(text)"]},{"cell_type":"code","source":["# PyTorch-based models\n","encoded_input = tokenizer(text, return_tensors='pt')\n","output = model(**encoded_input)\n","scores = output[0][0].detach().numpy()\n","scores = softmax(scores)\n","\n","# TensorFlow-based models\n","# model = TFAutoModelForSequenceClassification.from_pretrained(model_path)\n","# model.save_pretrained(model_path)\n","# text = \"Covid cases are increasing fast!\"\n","# encoded_input = tokenizer(text, return_tensors='tf')\n","# output = model(encoded_input)\n","# scores = output[0][0].numpy()\n","# scores = softmax(scores)"],"metadata":{"id":"YK-u5iu_VQBY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODIOxa2_1RuD","outputId":"a97f7bd6-3b8d-4482-ee9b-7b8f2603b12d","executionInfo":{"status":"ok","timestamp":1699369559773,"user_tz":0,"elapsed":102,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101,  2023,  2522, 17258,  2234,  2007,  2049,  2219, 11376,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cajFKjoc1gd2","outputId":"68d81eb1-df10-44ab-911a-87cc50dc98af","executionInfo":{"status":"ok","timestamp":1699369559773,"user_tz":0,"elapsed":56,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[-0.5647,  0.9987, -0.4073]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# score without softmax function\n","\n","output[0][0].detach().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrgTDGojjsvP","outputId":"b9e59aba-b4ee-441a-ea3e-73a22469a370","executionInfo":{"status":"ok","timestamp":1699369559774,"user_tz":0,"elapsed":52,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.5647182 ,  0.998708  , -0.40728953], dtype=float32)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#display score with softmax function\n","\n","scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWl9QV5UVr5C","outputId":"9d3b1699-3d53-4e94-fa84-c8ed1fc11430","executionInfo":{"status":"ok","timestamp":1699369559774,"user_tz":0,"elapsed":48,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.14397496, 0.6875027 , 0.16852231], dtype=float32)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Fkww3mkU2fU"},"outputs":[],"source":["config.id2label = {0: 'NEGATIVE', 1: 'NEUTRAL', 2: 'POSITIVE'}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8z4eQoeU2fV","outputId":"5a4f3796-225b-4d85-a863-e2f747b5ffcc","executionInfo":{"status":"ok","timestamp":1699369559775,"user_tz":0,"elapsed":46,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Classified text:This covid came with its own agenda\n","1) NEUTRAL 0.6875\n","2) POSITIVE 0.1685\n","3) NEGATIVE 0.144\n"]}],"source":["# Print labels and scores\n","ranking = np.argsort(scores)\n","ranking = ranking[::-1]\n","print (f\"Classified text:{text}\")\n","for i in range(scores.shape[0]):\n","    l = config.id2label[ranking[i]]\n","    s = scores[ranking[i]]\n","    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fI6bVakU2fV"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **GRADIO APP**"],"metadata":{"id":"pgPuLwE_xsIe"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import gradio as gr\n","import torch\n","\n","# Initialize the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"Afia-manubea/FineTuned-DistilBert-Model\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"Afia-manubea/FineTuned-DistilBert-Model\")\n","\n","def sentiment_analysis(text):\n","    # Tokenize the input text\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","    # Forward pass through the model\n","    with torch.no_grad():\n","        output = model(**inputs)\n","\n","    # Extract the predicted probabilities\n","    scores = torch.nn.functional.softmax(output.logits, dim=1).squeeze().tolist()\n","\n","    # Define the sentiment labels\n","    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n","\n","    # Create a dictionary of sentiment scores\n","    scores_dict = {label: score for label, score in zip(labels, scores)}\n","\n","    return scores_dict\n","\n","demo = gr.Interface(\n","    fn=sentiment_analysis,\n","    inputs=gr.Textbox(placeholder=\"Write/Type your tweet here\"),\n","    outputs=\"Tweet\",\n","    #intrepretation=\"default\",\n","    examples=[\n","        [\"Vaccine Who!, and where\"],\n","        [\"There's a global pandemic ongoing called Covid\"],\n","        [\"Covid is dangerous\"],\n","        [\"Covid is affecting Businesses badly\"],\n","        [\"This so-called Covid is not going to block our shine. Come to The beach this weekend! It's going to be lit\"],\n","    ],\n","    title=\"Covid Tweets Sentiment Analysis App\",\n","    description=\"This Application is the interface to Our Sentiment Analysis Model fine-tuned from a DistilBERT model.\",\n",")\n","\n","demo.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"fCaC9N3qhdj-","executionInfo":{"status":"ok","timestamp":1699963078631,"user_tz":0,"elapsed":6259,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}},"outputId":"600a7427-6e65-41c0-b6f5-8070f38531c9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://d660c4e02ceee91ee1.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://d660c4e02ceee91ee1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import gradio as gr\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","# Initialize the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"Afia-manubea/FineTuned-DistilBert-Model\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"Afia-manubea/FineTuned-DistilBert-Model\")\n","\n","def sentiment_analysis(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        output = model(**inputs)\n","    scores = torch.nn.functional.softmax(output.logits, dim=1).squeeze().tolist()\n","    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n","    scores_dict = {label: score for label, score in zip(labels, scores)}\n","    return scores_dict\n","\n","def home():\n","    return \"Welcome to the Covid Tweets Sentiment Analysis App!\"\n","\n","def predict(tweet):\n","    scores = sentiment_analysis(tweet)\n","    return f\"The sentiment of the tweet is: {max(scores, key=scores.get)}\"\n","\n","def about():\n","    return \"This application is an interface to our Sentiment Analysis Model fine-tuned from a DistilBERT model.\"\n","\n","\n","iface = gr.Interface(\n","    fn=home,\n","    inputs=\"text\",\n","    outputs=\"text\",\n","    title=\"Covid Tweets Sentiment Analysis App\",\n","    description=\"**Menu:**\\n\\n- [Home](this_fn='home')\\n- [Predict](this_fn='predict')\\n- [About](this_fn='about')\",\n","    examples=[\n","        [\"Vaccine Who!, and where\"],\n","        [\"There's a global pandemic ongoing called Covid\"],\n","        [\"Covid is dangerous\"],\n","        [\"Covid is affecting Businesses badly\"],\n","        [\"This so-called Covid is not going to block our shine. Come to The beach this weekend! It's going to be lit\"],\n","    ],\n",")\n","iface.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":711},"id":"qJpBWrQbMybQ","executionInfo":{"status":"ok","timestamp":1699921979719,"user_tz":0,"elapsed":11632,"user":{"displayName":"Florence Affoh","userId":"06590556898269399846"}},"outputId":"0eacf0f8-f2cf-44be-d476-21629b3ad979"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gradio/utils.py:819: UserWarning: Expected 0 arguments for function <function home at 0x7e3cabdb6e60>, received 1.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/gradio/utils.py:827: UserWarning: Expected maximum 0 arguments for function <function home at 0x7e3cabdb6e60>, received 1.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://040d83e88747e7cc52.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://040d83e88747e7cc52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":9}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1ab24538aa0da4b2d8c48eaca591ff7ffc54671225fb0511b432fd9e26a098ba"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}